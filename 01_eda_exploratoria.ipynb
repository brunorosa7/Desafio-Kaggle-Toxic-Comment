{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise Exploratória de Dados (EDA)\n",
    "## Jigsaw Toxic Comment Classification Challenge\n",
    "\n",
    "Este notebook realiza uma análise exploratória completa dos dados da competição."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Importação de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurações de visualização\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carregamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir caminhos\n",
    "data_dir = Path('../data/raw')\n",
    "\n",
    "# Carregar dados de treino\n",
    "print(\"Carregando train.csv...\")\n",
    "train_df = pd.read_csv(data_dir / 'train.csv')\n",
    "print(f\"Shape: {train_df.shape}\")\n",
    "\n",
    "# Carregar dados de teste\n",
    "print(\"\\nCarregando test.csv...\")\n",
    "test_df = pd.read_csv(data_dir / 'test.csv')\n",
    "print(f\"Shape: {test_df.shape}\")\n",
    "\n",
    "# Carregar sample submission\n",
    "print(\"\\nCarregando sample_submission.csv...\")\n",
    "sample_submission = pd.read_csv(data_dir / 'sample_submission.csv')\n",
    "print(f\"Shape: {sample_submission.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Primeira Visualização dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== DADOS DE TREINO ===\")\n",
    "print(f\"\\nPrimeiras linhas:\")\n",
    "display(train_df.head())\n",
    "\n",
    "print(f\"\\nInformações sobre o dataset:\")\n",
    "print(train_df.info())\n",
    "\n",
    "print(f\"\\nEstatísticas descritivas:\")\n",
    "display(train_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== DADOS DE TESTE ===\")\n",
    "print(f\"\\nPrimeiras linhas:\")\n",
    "display(test_df.head())\n",
    "\n",
    "print(f\"\\nInformações sobre o dataset:\")\n",
    "print(test_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Análise das Colunas de Toxicidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar colunas de toxicidade\n",
    "toxic_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "print(\"Colunas de toxicidade:\", toxic_cols)\n",
    "print(f\"\\nTotal de colunas no dataset: {len(train_df.columns)}\")\n",
    "print(f\"Colunas: {list(train_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatísticas das colunas de toxicidade\n",
    "print(\"=== ESTATÍSTICAS DAS CLASSES DE TOXICIDADE ===\")\n",
    "toxic_stats = train_df[toxic_cols].describe()\n",
    "display(toxic_stats)\n",
    "\n",
    "print(\"\\n=== CONTAGEM DE COMENTÁRIOS POR CLASSE ===\")\n",
    "for col in toxic_cols:\n",
    "    count = train_df[col].sum()\n",
    "    pct = (count / len(train_df)) * 100\n",
    "    print(f\"{col:20s}: {count:6d} ({pct:5.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualizações - Distribuição das Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de barras com a contagem de cada classe\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "counts = train_df[toxic_cols].sum().sort_values(ascending=False)\n",
    "counts.plot(kind='bar', ax=ax, color='coral')\n",
    "ax.set_title('Distribuição das Classes de Toxicidade', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Tipo de Toxicidade', fontsize=12)\n",
    "ax.set_ylabel('Número de Comentários', fontsize=12)\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Adicionar valores nas barras\n",
    "for i, v in enumerate(counts):\n",
    "    ax.text(i, v + 1000, f'{int(v):,}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de porcentagem\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "percentages = (train_df[toxic_cols].sum() / len(train_df) * 100).sort_values(ascending=False)\n",
    "percentages.plot(kind='bar', ax=ax, color='steelblue')\n",
    "ax.set_title('Percentual de Comentários por Classe de Toxicidade', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Tipo de Toxicidade', fontsize=12)\n",
    "ax.set_ylabel('Percentual (%)', fontsize=12)\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Adicionar valores nas barras\n",
    "for i, v in enumerate(percentages):\n",
    "    ax.text(i, v + 0.5, f'{v:.2f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Análise de Comentários Múltiplas Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar quantas classes cada comentário tem\n",
    "train_df['num_classes'] = train_df[toxic_cols].sum(axis=1)\n",
    "\n",
    "print(\"=== DISTRIBUIÇÃO DO NÚMERO DE CLASSES POR COMENTÁRIO ===\")\n",
    "class_distribution = train_df['num_classes'].value_counts().sort_index()\n",
    "print(class_distribution)\n",
    "\n",
    "print(f\"\\nComentários sem toxicidade (0 classes): {class_distribution.get(0, 0):,}\")\n",
    "print(f\"Comentários com pelo menos 1 classe: {(train_df['num_classes'] > 0).sum():,}\")\n",
    "print(f\"Comentários com múltiplas classes (2+): {(train_df['num_classes'] >= 2).sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização da distribuição\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "class_distribution.plot(kind='bar', ax=ax, color='mediumseagreen')\n",
    "ax.set_title('Distribuição do Número de Classes por Comentário', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Número de Classes', fontsize=12)\n",
    "ax.set_ylabel('Número de Comentários', fontsize=12)\n",
    "\n",
    "# Adicionar valores nas barras\n",
    "for i, v in enumerate(class_distribution):\n",
    "    ax.text(i, v + 5000, f'{int(v):,}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Análise de Correlação entre Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlação\n",
    "correlation_matrix = train_df[toxic_cols].corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8}, ax=ax)\n",
    "ax.set_title('Matriz de Correlação entre Classes de Toxicidade', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Análise do Texto dos Comentários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatísticas básicas sobre o texto\n",
    "train_df['comment_length'] = train_df['comment_text'].str.len()\n",
    "train_df['word_count'] = train_df['comment_text'].str.split().str.len()\n",
    "\n",
    "print(\"=== ESTATÍSTICAS DO TEXTO ===\")\n",
    "print(f\"Comprimento médio dos comentários: {train_df['comment_length'].mean():.0f} caracteres\")\n",
    "print(f\"Comprimento mediano dos comentários: {train_df['comment_length'].median():.0f} caracteres\")\n",
    "print(f\"Número médio de palavras: {train_df['word_count'].mean():.1f} palavras\")\n",
    "print(f\"Número mediano de palavras: {train_df['word_count'].median():.1f} palavras\")\n",
    "print(f\"\\nComentário mais curto: {train_df['comment_length'].min()} caracteres\")\n",
    "print(f\"Comentário mais longo: {train_df['comment_length'].max()} caracteres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuição do comprimento dos comentários\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Histograma do comprimento\n",
    "axes[0].hist(train_df['comment_length'], bins=50, color='skyblue', edgecolor='black')\n",
    "axes[0].set_title('Distribuição do Comprimento dos Comentários', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Número de Caracteres', fontsize=10)\n",
    "axes[0].set_ylabel('Frequência', fontsize=10)\n",
    "axes[0].axvline(train_df['comment_length'].mean(), color='red', linestyle='--', \n",
    "                label=f'Média: {train_df[\"comment_length\"].mean():.0f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Histograma do número de palavras\n",
    "axes[1].hist(train_df['word_count'], bins=50, color='lightcoral', edgecolor='black')\n",
    "axes[1].set_title('Distribuição do Número de Palavras', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Número de Palavras', fontsize=10)\n",
    "axes[1].set_ylabel('Frequência', fontsize=10)\n",
    "axes[1].axvline(train_df['word_count'].mean(), color='red', linestyle='--', \n",
    "                label=f'Média: {train_df[\"word_count\"].mean():.1f}')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Exemplos de Comentários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplos de comentários não tóxicos\n",
    "print(\"=== EXEMPLOS DE COMENTÁRIOS NÃO TÓXICOS ===\")\n",
    "non_toxic = train_df[train_df['num_classes'] == 0]\n",
    "for idx, row in non_toxic.head(3).iterrows():\n",
    "    print(f\"\\nID: {row['id']}\")\n",
    "    print(f\"Texto: {row['comment_text'][:200]}...\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplos de comentários tóxicos\n",
    "print(\"=== EXEMPLOS DE COMENTÁRIOS TÓXICOS ===\")\n",
    "toxic = train_df[train_df['num_classes'] > 0]\n",
    "for idx, row in toxic.head(3).iterrows():\n",
    "    print(f\"\\nID: {row['id']}\")\n",
    "    classes = [col for col in toxic_cols if row[col] == 1]\n",
    "    print(f\"Classes: {', '.join(classes)}\")\n",
    "    print(f\"Texto: {row['comment_text'][:200]}...\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Resumo e Conclusões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== RESUMO DA ANÁLISE EXPLORATÓRIA ===\")\n",
    "print(f\"\\n1. Dataset de Treino:\")\n",
    "print(f\"   - Total de comentários: {len(train_df):,}\")\n",
    "print(f\"   - Comentários não tóxicos: {(train_df['num_classes'] == 0).sum():,} ({(train_df['num_classes'] == 0).sum()/len(train_df)*100:.2f}%)\")\n",
    "print(f\"   - Comentários tóxicos: {(train_df['num_classes'] > 0).sum():,} ({(train_df['num_classes'] > 0).sum()/len(train_df)*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\n2. Distribuição das Classes:\")\n",
    "for col in toxic_cols:\n",
    "    count = train_df[col].sum()\n",
    "    pct = (count / len(train_df)) * 100\n",
    "    print(f\"   - {col:20s}: {count:6,} ({pct:5.2f}%)\")\n",
    "\n",
    "print(f\"\\n3. Características do Texto:\")\n",
    "print(f\"   - Comprimento médio: {train_df['comment_length'].mean():.0f} caracteres\")\n",
    "print(f\"   - Palavras médias: {train_df['word_count'].mean():.1f} palavras\")\n",
    "\n",
    "print(f\"\\n4. Dataset de Teste:\")\n",
    "print(f\"   - Total de comentários: {len(test_df):,}\")\n",
    "\n",
    "print(\"\\n=== PRÓXIMOS PASSOS ===\")\n",
    "print(\"1. Pré-processamento de texto\")\n",
    "print(\"2. Feature engineering\")\n",
    "print(\"3. Treinamento de modelos\")\n",
    "print(\"4. Avaliação e otimização\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

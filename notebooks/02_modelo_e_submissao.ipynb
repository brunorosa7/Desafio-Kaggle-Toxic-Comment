{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modelo e Submissão para Kaggle\n",
        "## Jigsaw Toxic Comment Classification Challenge\n",
        "\n",
        "Este notebook treina um modelo e gera o arquivo de submissão para o Kaggle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Importação de Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "# Processamento de texto\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "\n",
        "print(\"Bibliotecas importadas com sucesso!\")\n",
        "\n",
        "# Baixar recursos do NLTK (se necessário)\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt', quiet=True)\n",
        "\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except LookupError:\n",
        "    nltk.download('stopwords', quiet=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bibliotecas importadas com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Carregamento dos Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Definir caminhos\n",
        "data_dir = Path('../data/raw')\n",
        "\n",
        "# Carregar dados\n",
        "print(\"Carregando dados de treino...\")\n",
        "train_df = pd.read_csv(data_dir / 'train.csv')\n",
        "print(f\"Shape: {train_df.shape}\")\n",
        "\n",
        "print(\"\\nCarregando dados de teste...\")\n",
        "test_df = pd.read_csv(data_dir / 'test.csv')\n",
        "print(f\"Shape: {test_df.shape}\")\n",
        "\n",
        "print(\"\\nCarregando sample submission...\")\n",
        "sample_submission = pd.read_csv(data_dir / 'sample_submission.csv')\n",
        "print(f\"Shape: {sample_submission.shape}\")\n",
        "\n",
        "# Colunas de toxicidade\n",
        "toxic_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "print(f\"\\nClasses de toxicidade: {toxic_cols}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando dados de treino...\n",
            "Shape: (159571, 8)\n",
            "\n",
            "Carregando dados de teste...\n",
            "Shape: (153164, 2)\n",
            "\n",
            "Carregando sample submission...\n",
            "Shape: (153164, 7)\n",
            "\n",
            "Classes de toxicidade: ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Pré-processamento de Texto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Pré-processa o texto:\n",
        "    - Remove URLs\n",
        "    - Remove caracteres especiais\n",
        "    - Converte para minúsculas\n",
        "    - Remove espaços extras\n",
        "    \"\"\"\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    \n",
        "    # Converter para string\n",
        "    text = str(text)\n",
        "    \n",
        "    # Remover URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    \n",
        "    # Remover caracteres especiais, manter apenas letras, números e espaços\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    \n",
        "    # Converter para minúsculas\n",
        "    text = text.lower()\n",
        "    \n",
        "    # Remover espaços extras\n",
        "    text = ' '.join(text.split())\n",
        "    \n",
        "    return text\n",
        "\n",
        "# Aplicar pré-processamento\n",
        "print(\"Pré-processando textos de treino...\")\n",
        "train_df['comment_text_processed'] = train_df['comment_text'].apply(preprocess_text)\n",
        "\n",
        "print(\"Pré-processando textos de teste...\")\n",
        "test_df['comment_text_processed'] = test_df['comment_text'].apply(preprocess_text)\n",
        "\n",
        "print(\"\\nExemplo de texto original:\")\n",
        "print(train_df['comment_text'].iloc[0][:200])\n",
        "print(\"\\nExemplo de texto processado:\")\n",
        "print(train_df['comment_text_processed'].iloc[0][:200])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pré-processando textos de treino...\n",
            "Pré-processando textos de teste...\n",
            "\n",
            "Exemplo de texto original:\n",
            "Explanation\n",
            "Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove th\n",
            "\n",
            "Exemplo de texto processado:\n",
            "explanation why the edits made under my username hardcore metallica fan were reverted they werent vandalisms just closure on some gas after i voted at new york dolls fac and please dont remove the tem\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Feature Engineering - TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Criar vetorizador TF-IDF\n",
        "# Limitar o número de features para não consumir muita memória\n",
        "max_features = 5000\n",
        "\n",
        "print(f\"Criando vetorizador TF-IDF com max_features={max_features}...\")\n",
        "vectorizer = TfidfVectorizer(\n",
        "    max_features=max_features,\n",
        "    ngram_range=(1, 2),  # Unigramas e bigramas\n",
        "    min_df=2,  # Palavra deve aparecer em pelo menos 2 documentos\n",
        "    max_df=0.95,  # Palavra não deve aparecer em mais de 95% dos documentos\n",
        "    stop_words='english'\n",
        ")\n",
        "\n",
        "# Treinar o vetorizador e transformar dados de treino\n",
        "print(\"\\nTreinando vetorizador e transformando dados de treino...\")\n",
        "X_train = vectorizer.fit_transform(train_df['comment_text_processed'])\n",
        "print(f\"Shape dos dados de treino: {X_train.shape}\")\n",
        "\n",
        "# Transformar dados de teste\n",
        "print(\"\\nTransformando dados de teste...\")\n",
        "X_test = vectorizer.transform(test_df['comment_text_processed'])\n",
        "print(f\"Shape dos dados de teste: {X_test.shape}\")\n",
        "\n",
        "# Labels\n",
        "y_train = train_df[toxic_cols].values\n",
        "print(f\"\\nShape dos labels: {y_train.shape}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Criando vetorizador TF-IDF com max_features=5000...\n",
            "\n",
            "Treinando vetorizador e transformando dados de treino...\n",
            "Shape dos dados de treino: (159571, 5000)\n",
            "\n",
            "Transformando dados de teste...\n",
            "Shape dos dados de teste: (153164, 5000)\n",
            "\n",
            "Shape dos labels: (159571, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Divisão dos Dados (Treino/Validação)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Dividir dados de treino em treino e validação\n",
        "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
        "    X_train, y_train, \n",
        "    test_size=0.2, \n",
        "    random_state=42,\n",
        "    stratify=None  # Não estratificar porque temos múltiplas classes\n",
        ")\n",
        "\n",
        "print(f\"Dados de treino: {X_train_split.shape}\")\n",
        "print(f\"Dados de validação: {X_val_split.shape}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dados de treino: (127656, 5000)\n",
            "Dados de validação: (31915, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Treinamento do Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Usar OneVsRestClassifier com LogisticRegression\n",
        "# Isso treina um classificador binário para cada classe\n",
        "print(\"Treinando modelo (OneVsRest + LogisticRegression)...\")\n",
        "print(\"Isso pode levar alguns minutos...\")\n",
        "\n",
        "model = OneVsRestClassifier(\n",
        "    LogisticRegression(\n",
        "        max_iter=1000,\n",
        "        random_state=42,\n",
        "        solver='lbfgs',\n",
        "        C=1.0\n",
        "    ),\n",
        "    n_jobs=-1  # Usar todos os cores disponíveis\n",
        ")\n",
        "\n",
        "# Treinar o modelo\n",
        "model.fit(X_train_split, y_train_split)\n",
        "\n",
        "print(\"\\nModelo treinado com sucesso!\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Treinando modelo (OneVsRest + LogisticRegression)...\n",
            "Isso pode levar alguns minutos...\n",
            "\n",
            "Modelo treinado com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Avaliação do Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fazer previsões no conjunto de validação\n",
        "print(\"Fazendo previsões no conjunto de validação...\")\n",
        "y_val_pred = model.predict_proba(X_val_split)\n",
        "\n",
        "# Calcular ROC-AUC para cada classe\n",
        "print(\"\\n=== Métricas de Validação ===\")\n",
        "scores = {}\n",
        "for i, col in enumerate(toxic_cols):\n",
        "    score = roc_auc_score(y_val_split[:, i], y_val_pred[:, i])\n",
        "    scores[col] = score\n",
        "    print(f\"{col:20s}: {score:.4f}\")\n",
        "\n",
        "# Média dos scores\n",
        "mean_score = np.mean(list(scores.values()))\n",
        "print(f\"\\n{'Média':20s}: {mean_score:.4f}\")\n",
        "print(\"\\n(Quanto maior, melhor. Score máximo é 1.0)\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fazendo previsões no conjunto de validação...\n",
            "\n",
            "=== Métricas de Validação ===\n",
            "toxic               : 0.9586\n",
            "severe_toxic        : 0.9758\n",
            "obscene             : 0.9772\n",
            "threat              : 0.9812\n",
            "insult              : 0.9688\n",
            "identity_hate       : 0.9561\n",
            "\n",
            "Média               : 0.9696\n",
            "\n",
            "(Quanto maior, melhor. Score máximo é 1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Previsões no Conjunto de Teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Treinar modelo final com todos os dados de treino\n",
        "print(\"Treinando modelo final com todos os dados de treino...\")\n",
        "model_final = OneVsRestClassifier(\n",
        "    LogisticRegression(\n",
        "        max_iter=1000,\n",
        "        random_state=42,\n",
        "        solver='lbfgs',\n",
        "        C=1.0\n",
        "    ),\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "model_final.fit(X_train, y_train)\n",
        "print(\"Modelo final treinado!\")\n",
        "\n",
        "# Fazer previsões no conjunto de teste\n",
        "print(\"\\nFazendo previsões no conjunto de teste...\")\n",
        "test_predictions = model_final.predict_proba(X_test)\n",
        "print(f\"Shape das previsões: {test_predictions.shape}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Treinando modelo final com todos os dados de treino...\n",
            "Modelo final treinado!\n",
            "\n",
            "Fazendo previsões no conjunto de teste...\n",
            "Shape das previsões: (153164, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Criar Arquivo de Submissão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Criar DataFrame de submissão\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id']\n",
        "})\n",
        "\n",
        "# Adicionar previsões para cada classe\n",
        "for i, col in enumerate(toxic_cols):\n",
        "    submission[col] = test_predictions[:, i]\n",
        "\n",
        "# Verificar formato\n",
        "print(\"=== Formato da Submissão ===\")\n",
        "print(f\"Shape: {submission.shape}\")\n",
        "print(f\"\\nPrimeiras linhas:\")\n",
        "display(submission.head())\n",
        "\n",
        "print(f\"\\nEstatísticas das previsões:\")\n",
        "display(submission[toxic_cols].describe())\n",
        "\n",
        "# Verificar se está no formato correto\n",
        "print(f\"\\nColunas esperadas: {list(sample_submission.columns)}\")\n",
        "print(f\"Colunas criadas: {list(submission.columns)}\")\n",
        "assert list(submission.columns) == list(sample_submission.columns), \"Colunas não correspondem!\"\n",
        "print(\"\\n✓ Formato correto!\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== Formato da Submissão ===\n",
            "Shape: (153164, 7)\n",
            "\n",
            "Primeiras linhas:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>0.995305</td>\n",
              "      <td>0.147074</td>\n",
              "      <td>0.994955</td>\n",
              "      <td>0.026196</td>\n",
              "      <td>0.923182</td>\n",
              "      <td>0.271023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>0.008492</td>\n",
              "      <td>0.003082</td>\n",
              "      <td>0.006626</td>\n",
              "      <td>0.001479</td>\n",
              "      <td>0.007976</td>\n",
              "      <td>0.003164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>0.017330</td>\n",
              "      <td>0.001493</td>\n",
              "      <td>0.005017</td>\n",
              "      <td>0.000777</td>\n",
              "      <td>0.006776</td>\n",
              "      <td>0.001579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>0.005377</td>\n",
              "      <td>0.002018</td>\n",
              "      <td>0.003994</td>\n",
              "      <td>0.000880</td>\n",
              "      <td>0.003533</td>\n",
              "      <td>0.001033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00017695ad8997eb</td>\n",
              "      <td>0.061986</td>\n",
              "      <td>0.002646</td>\n",
              "      <td>0.014106</td>\n",
              "      <td>0.001266</td>\n",
              "      <td>0.021166</td>\n",
              "      <td>0.002553</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
              "0  00001cee341fdb12  0.995305      0.147074  0.994955  0.026196  0.923182   \n",
              "1  0000247867823ef7  0.008492      0.003082  0.006626  0.001479  0.007976   \n",
              "2  00013b17ad220c46  0.017330      0.001493  0.005017  0.000777  0.006776   \n",
              "3  00017563c3f7919a  0.005377      0.002018  0.003994  0.000880  0.003533   \n",
              "4  00017695ad8997eb  0.061986      0.002646  0.014106  0.001266  0.021166   \n",
              "\n",
              "   identity_hate  \n",
              "0       0.271023  \n",
              "1       0.003164  \n",
              "2       0.001579  \n",
              "3       0.001033  \n",
              "4       0.002553  "
            ]
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Estatísticas das previsões:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>153164.000000</td>\n",
              "      <td>153164.000000</td>\n",
              "      <td>153164.000000</td>\n",
              "      <td>153164.000000</td>\n",
              "      <td>153164.000000</td>\n",
              "      <td>153164.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.192169</td>\n",
              "      <td>0.017377</td>\n",
              "      <td>0.113866</td>\n",
              "      <td>0.004982</td>\n",
              "      <td>0.096087</td>\n",
              "      <td>0.016878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.317059</td>\n",
              "      <td>0.067973</td>\n",
              "      <td>0.256959</td>\n",
              "      <td>0.033443</td>\n",
              "      <td>0.214843</td>\n",
              "      <td>0.074337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000036</td>\n",
              "      <td>0.000045</td>\n",
              "      <td>0.000187</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000069</td>\n",
              "      <td>0.000037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.009991</td>\n",
              "      <td>0.001710</td>\n",
              "      <td>0.006272</td>\n",
              "      <td>0.000906</td>\n",
              "      <td>0.005252</td>\n",
              "      <td>0.001641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.029951</td>\n",
              "      <td>0.003024</td>\n",
              "      <td>0.012770</td>\n",
              "      <td>0.001342</td>\n",
              "      <td>0.012456</td>\n",
              "      <td>0.003225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.171244</td>\n",
              "      <td>0.005669</td>\n",
              "      <td>0.036087</td>\n",
              "      <td>0.001970</td>\n",
              "      <td>0.042947</td>\n",
              "      <td>0.006409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.993290</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.984673</td>\n",
              "      <td>0.999997</td>\n",
              "      <td>0.998147</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               toxic   severe_toxic        obscene         threat  \\\n",
              "count  153164.000000  153164.000000  153164.000000  153164.000000   \n",
              "mean        0.192169       0.017377       0.113866       0.004982   \n",
              "std         0.317059       0.067973       0.256959       0.033443   \n",
              "min         0.000036       0.000045       0.000187       0.000093   \n",
              "25%         0.009991       0.001710       0.006272       0.000906   \n",
              "50%         0.029951       0.003024       0.012770       0.001342   \n",
              "75%         0.171244       0.005669       0.036087       0.001970   \n",
              "max         1.000000       0.993290       1.000000       0.984673   \n",
              "\n",
              "              insult  identity_hate  \n",
              "count  153164.000000  153164.000000  \n",
              "mean        0.096087       0.016878  \n",
              "std         0.214843       0.074337  \n",
              "min         0.000069       0.000037  \n",
              "25%         0.005252       0.001641  \n",
              "50%         0.012456       0.003225  \n",
              "75%         0.042947       0.006409  \n",
              "max         0.999997       0.998147  "
            ]
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Colunas esperadas: ['id', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
            "Colunas criadas: ['id', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
            "\n",
            "✓ Formato correto!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Salvar Arquivo de Submissão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Criar diretório para submissões\n",
        "submission_dir = Path('../submissions')\n",
        "submission_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Salvar arquivo de submissão\n",
        "from datetime import datetime\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "filename = f'submission_{timestamp}.csv'\n",
        "filepath = submission_dir / filename\n",
        "\n",
        "submission.to_csv(filepath, index=False)\n",
        "print(f\"Arquivo de submissão salvo em: {filepath}\")\n",
        "print(f\"Tamanho do arquivo: {filepath.stat().st_size / 1024:.2f} KB\")\n",
        "\n",
        "# Também salvar como submission.csv (mais fácil de encontrar)\n",
        "submission.to_csv(submission_dir / 'submission.csv', index=False)\n",
        "print(f\"\\nTambém salvo como: {submission_dir / 'submission.csv'}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Arquivo de submissão salvo em: ..\\submissions\\submission_20260121_192044.csv\n",
            "Tamanho do arquivo: 21492.82 KB\n",
            "\n",
            "Também salvo como: ..\\submissions\\submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Instruções para Submeter no Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Passo a Passo para Submeter no Kaggle:\n",
        "\n",
        "1. **Acesse a página da competição:**\n",
        "   - https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge\n",
        "\n",
        "2. **Vá para a aba \"Submit Predictions\"** (ou \"Submeter Previsões\")\n",
        "\n",
        "3. **Clique em \"Upload Submission File\"**\n",
        "\n",
        "4. **Selecione o arquivo:**\n",
        "   - `submissions/submission.csv` ou o arquivo com timestamp\n",
        "\n",
        "5. **Clique em \"Make Submission\"**\n",
        "\n",
        "6. **Aguarde o processamento** (pode levar alguns minutos)\n",
        "\n",
        "7. **Veja seu score!** O Kaggle mostrará sua pontuação (ROC-AUC médio)\n",
        "\n",
        "### Dicas:\n",
        "- Você pode submeter até 5 vezes por dia\n",
        "- O score público é calculado em uma parte do conjunto de teste\n",
        "- O score privado (final) é calculado após o encerramento da competição\n",
        "- Tente melhorar o modelo e submeter novamente!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Conclusão e Trabalhos Futuros\n",
        "\n",
        "### Resultados Obtidos\n",
        "\n",
        "Este projeto desenvolveu com sucesso um modelo de classificação multirrótulo capaz de identificar comentários tóxicos com um score ROC-AUC médio de **0.9696 (96.96%)** no conjunto de validação. A solução utiliza técnicas consolidadas de NLP (TF-IDF) combinadas com algoritmos de Machine Learning (Regressão Logística), demonstrando eficácia na tarefa proposta.\n",
        "\n",
        "### Trabalhos Futuros\n",
        "\n",
        "Para melhorar ainda mais o desempenho do modelo, as seguintes abordagens podem ser exploradas:\n",
        "\n",
        "1. **Modelos de Deep Learning**:\n",
        "   - Implementação de redes neurais recorrentes (LSTM, GRU) para capturar dependências temporais\n",
        "   - Fine-tuning de modelos pré-treinados como **BERT**, **DistilBERT** ou **RoBERTa** para aproveitar conhecimento semântico avançado\n",
        "   - Arquiteturas Transformer para processamento de sequências longas\n",
        "\n",
        "2. **Feature Engineering Avançado**:\n",
        "   - Incorporação de word embeddings pré-treinados (Word2Vec, GloVe, FastText)\n",
        "   - Aumento do número de features TF-IDF e exploração de n-gramas maiores (trigramas)\n",
        "   - Extração de features linguísticas adicionais (comprimento do texto, densidade de palavras-chave, etc.)\n",
        "\n",
        "3. **Otimização de Hiperparâmetros**:\n",
        "   - Utilização de técnicas como GridSearch ou RandomizedSearch para encontrar os melhores parâmetros\n",
        "   - Implementação de validação cruzada para avaliação mais robusta\n",
        "   - Ajuste fino do parâmetro de regularização C na Regressão Logística\n",
        "\n",
        "4. **Tratamento de Classes Desbalanceadas**:\n",
        "   - Aplicação de técnicas como SMOTE para balanceamento sintético\n",
        "   - Uso de class weights para dar mais importância a classes minoritárias\n",
        "   - Implementação de Focal Loss para focar em exemplos difíceis de classificar\n",
        "\n",
        "5. **Ensemble de Modelos**:\n",
        "   - Combinação de múltiplos modelos (XGBoost, LightGBM, CatBoost) através de voting ou stacking\n",
        "   - Integração de diferentes representações de texto (TF-IDF + Word Embeddings)\n",
        "\n",
        "### Considerações Finais\n",
        "\n",
        "A solução apresentada demonstra uma abordagem sistemática e bem fundamentada para o problema de classificação de comentários tóxicos, utilizando técnicas estabelecidas de Machine Learning. O modelo desenvolvido é eficiente, interpretável e alcança resultados competitivos, servindo como uma base sólida para futuras melhorias e explorações de técnicas mais avançadas.\n",
        "\n",
        "---\n",
        "\n",
        "**Bibliotecas Utilizadas:**\n",
        "- pandas, numpy: Manipulação de dados\n",
        "- scikit-learn: Machine Learning (TfidfVectorizer, LogisticRegression, OneVsRestClassifier)\n",
        "- nltk: Processamento de linguagem natural\n",
        "- re: Expressões regulares"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ideias para melhorar a pontuação:\n",
        "\n",
        "1. **Pré-processamento mais avançado:**\n",
        "   - Lemmatização/Stemming\n",
        "   - Remoção de stopwords mais inteligente\n",
        "   - Tratamento de emojis e caracteres especiais\n",
        "\n",
        "2. **Feature Engineering:**\n",
        "   - Aumentar max_features do TF-IDF\n",
        "   - Usar n-gramas maiores (trigramas)\n",
        "   - Adicionar features de comprimento do texto\n",
        "   - Word embeddings (Word2Vec, GloVe, FastText)\n",
        "\n",
        "3. **Modelos mais avançados:**\n",
        "   - XGBoost, LightGBM, CatBoost\n",
        "   - Redes Neurais (LSTM, BERT, DistilBERT)\n",
        "   - Ensemble de modelos\n",
        "\n",
        "4. **Otimização de hiperparâmetros:**\n",
        "   - GridSearch ou RandomizedSearch\n",
        "   - Validação cruzada\n",
        "\n",
        "5. **Tratamento de classes desbalanceadas:**\n",
        "   - SMOTE\n",
        "   - Class weights\n",
        "   - Focal Loss"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo e Submissão para Kaggle\n",
    "## Jigsaw Toxic Comment Classification Challenge\n",
    "\n",
    "Este notebook treina um modelo e gera o arquivo de submissão para o Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importação de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Processamento de texto\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "print(\"Bibliotecas importadas com sucesso!\")\n",
    "\n",
    "# Baixar recursos do NLTK (se necessário)\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt', quiet=True)\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords', quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carregamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir caminhos\n",
    "data_dir = Path('../data/raw')\n",
    "\n",
    "# Carregar dados\n",
    "print(\"Carregando dados de treino...\")\n",
    "train_df = pd.read_csv(data_dir / 'train.csv')\n",
    "print(f\"Shape: {train_df.shape}\")\n",
    "\n",
    "print(\"\\nCarregando dados de teste...\")\n",
    "test_df = pd.read_csv(data_dir / 'test.csv')\n",
    "print(f\"Shape: {test_df.shape}\")\n",
    "\n",
    "print(\"\\nCarregando sample submission...\")\n",
    "sample_submission = pd.read_csv(data_dir / 'sample_submission.csv')\n",
    "print(f\"Shape: {sample_submission.shape}\")\n",
    "\n",
    "# Colunas de toxicidade\n",
    "toxic_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "print(f\"\\nClasses de toxicidade: {toxic_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pré-processamento de Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Pré-processa o texto:\n",
    "    - Remove URLs\n",
    "    - Remove caracteres especiais\n",
    "    - Converte para minúsculas\n",
    "    - Remove espaços extras\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    # Converter para string\n",
    "    text = str(text)\n",
    "    \n",
    "    # Remover URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remover caracteres especiais, manter apenas letras, números e espaços\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    \n",
    "    # Converter para minúsculas\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remover espaços extras\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Aplicar pré-processamento\n",
    "print(\"Pré-processando textos de treino...\")\n",
    "train_df['comment_text_processed'] = train_df['comment_text'].apply(preprocess_text)\n",
    "\n",
    "print(\"Pré-processando textos de teste...\")\n",
    "test_df['comment_text_processed'] = test_df['comment_text'].apply(preprocess_text)\n",
    "\n",
    "print(\"\\nExemplo de texto original:\")\n",
    "print(train_df['comment_text'].iloc[0][:200])\n",
    "print(\"\\nExemplo de texto processado:\")\n",
    "print(train_df['comment_text_processed'].iloc[0][:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering - TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar vetorizador TF-IDF\n",
    "# Limitar o número de features para não consumir muita memória\n",
    "max_features = 5000\n",
    "\n",
    "print(f\"Criando vetorizador TF-IDF com max_features={max_features}...\")\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=max_features,\n",
    "    ngram_range=(1, 2),  # Unigramas e bigramas\n",
    "    min_df=2,  # Palavra deve aparecer em pelo menos 2 documentos\n",
    "    max_df=0.95,  # Palavra não deve aparecer em mais de 95% dos documentos\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "# Treinar o vetorizador e transformar dados de treino\n",
    "print(\"\\nTreinando vetorizador e transformando dados de treino...\")\n",
    "X_train = vectorizer.fit_transform(train_df['comment_text_processed'])\n",
    "print(f\"Shape dos dados de treino: {X_train.shape}\")\n",
    "\n",
    "# Transformar dados de teste\n",
    "print(\"\\nTransformando dados de teste...\")\n",
    "X_test = vectorizer.transform(test_df['comment_text_processed'])\n",
    "print(f\"Shape dos dados de teste: {X_test.shape}\")\n",
    "\n",
    "# Labels\n",
    "y_train = train_df[toxic_cols].values\n",
    "print(f\"\\nShape dos labels: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Divisão dos Dados (Treino/Validação)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir dados de treino em treino e validação\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train, y_train, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=None  # Não estratificar porque temos múltiplas classes\n",
    ")\n",
    "\n",
    "print(f\"Dados de treino: {X_train_split.shape}\")\n",
    "print(f\"Dados de validação: {X_val_split.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Treinamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar OneVsRestClassifier com LogisticRegression\n",
    "# Isso treina um classificador binário para cada classe\n",
    "print(\"Treinando modelo (OneVsRest + LogisticRegression)...\")\n",
    "print(\"Isso pode levar alguns minutos...\")\n",
    "\n",
    "model = OneVsRestClassifier(\n",
    "    LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        random_state=42,\n",
    "        solver='lbfgs',\n",
    "        C=1.0\n",
    "    ),\n",
    "    n_jobs=-1  # Usar todos os cores disponíveis\n",
    ")\n",
    "\n",
    "# Treinar o modelo\n",
    "model.fit(X_train_split, y_train_split)\n",
    "\n",
    "print(\"\\nModelo treinado com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Avaliação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer previsões no conjunto de validação\n",
    "print(\"Fazendo previsões no conjunto de validação...\")\n",
    "y_val_pred = model.predict_proba(X_val_split)\n",
    "\n",
    "# Calcular ROC-AUC para cada classe\n",
    "print(\"\\n=== Métricas de Validação ===\")\n",
    "scores = {}\n",
    "for i, col in enumerate(toxic_cols):\n",
    "    score = roc_auc_score(y_val_split[:, i], y_val_pred[:, i])\n",
    "    scores[col] = score\n",
    "    print(f\"{col:20s}: {score:.4f}\")\n",
    "\n",
    "# Média dos scores\n",
    "mean_score = np.mean(list(scores.values()))\n",
    "print(f\"\\n{'Média':20s}: {mean_score:.4f}\")\n",
    "print(\"\\n(Quanto maior, melhor. Score máximo é 1.0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Previsões no Conjunto de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar modelo final com todos os dados de treino\n",
    "print(\"Treinando modelo final com todos os dados de treino...\")\n",
    "model_final = OneVsRestClassifier(\n",
    "    LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        random_state=42,\n",
    "        solver='lbfgs',\n",
    "        C=1.0\n",
    "    ),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model_final.fit(X_train, y_train)\n",
    "print(\"Modelo final treinado!\")\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "print(\"\\nFazendo previsões no conjunto de teste...\")\n",
    "test_predictions = model_final.predict_proba(X_test)\n",
    "print(f\"Shape das previsões: {test_predictions.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Criar Arquivo de Submissão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar DataFrame de submissão\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id']\n",
    "})\n",
    "\n",
    "# Adicionar previsões para cada classe\n",
    "for i, col in enumerate(toxic_cols):\n",
    "    submission[col] = test_predictions[:, i]\n",
    "\n",
    "# Verificar formato\n",
    "print(\"=== Formato da Submissão ===\")\n",
    "print(f\"Shape: {submission.shape}\")\n",
    "print(f\"\\nPrimeiras linhas:\")\n",
    "display(submission.head())\n",
    "\n",
    "print(f\"\\nEstatísticas das previsões:\")\n",
    "display(submission[toxic_cols].describe())\n",
    "\n",
    "# Verificar se está no formato correto\n",
    "print(f\"\\nColunas esperadas: {list(sample_submission.columns)}\")\n",
    "print(f\"Colunas criadas: {list(submission.columns)}\")\n",
    "assert list(submission.columns) == list(sample_submission.columns), \"Colunas não correspondem!\"\n",
    "print(\"\\n✓ Formato correto!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Salvar Arquivo de Submissão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar diretório para submissões\n",
    "submission_dir = Path('../submissions')\n",
    "submission_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Salvar arquivo de submissão\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "filename = f'submission_{timestamp}.csv'\n",
    "filepath = submission_dir / filename\n",
    "\n",
    "submission.to_csv(filepath, index=False)\n",
    "print(f\"Arquivo de submissão salvo em: {filepath}\")\n",
    "print(f\"Tamanho do arquivo: {filepath.stat().st_size / 1024:.2f} KB\")\n",
    "\n",
    "# Também salvar como submission.csv (mais fácil de encontrar)\n",
    "submission.to_csv(submission_dir / 'submission.csv', index=False)\n",
    "print(f\"\\nTambém salvo como: {submission_dir / 'submission.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Instruções para Submeter no Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo a Passo para Submeter no Kaggle:\n",
    "\n",
    "1. **Acesse a página da competição:**\n",
    "   - https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge\n",
    "\n",
    "2. **Vá para a aba \"Submit Predictions\"** (ou \"Submeter Previsões\")\n",
    "\n",
    "3. **Clique em \"Upload Submission File\"**\n",
    "\n",
    "4. **Selecione o arquivo:**\n",
    "   - `submissions/submission.csv` ou o arquivo com timestamp\n",
    "\n",
    "5. **Clique em \"Make Submission\"**\n",
    "\n",
    "6. **Aguarde o processamento** (pode levar alguns minutos)\n",
    "\n",
    "7. **Veja seu score!** O Kaggle mostrará sua pontuação (ROC-AUC médio)\n",
    "\n",
    "### Dicas:\n",
    "- Você pode submeter até 5 vezes por dia\n",
    "- O score público é calculado em uma parte do conjunto de teste\n",
    "- O score privado (final) é calculado após o encerramento da competição\n",
    "- Tente melhorar o modelo e submeter novamente!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Próximos Passos para Melhorar o Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideias para melhorar a pontuação:\n",
    "\n",
    "1. **Pré-processamento mais avançado:**\n",
    "   - Lemmatização/Stemming\n",
    "   - Remoção de stopwords mais inteligente\n",
    "   - Tratamento de emojis e caracteres especiais\n",
    "\n",
    "2. **Feature Engineering:**\n",
    "   - Aumentar max_features do TF-IDF\n",
    "   - Usar n-gramas maiores (trigramas)\n",
    "   - Adicionar features de comprimento do texto\n",
    "   - Word embeddings (Word2Vec, GloVe, FastText)\n",
    "\n",
    "3. **Modelos mais avançados:**\n",
    "   - XGBoost, LightGBM, CatBoost\n",
    "   - Redes Neurais (LSTM, BERT, DistilBERT)\n",
    "   - Ensemble de modelos\n",
    "\n",
    "4. **Otimização de hiperparâmetros:**\n",
    "   - GridSearch ou RandomizedSearch\n",
    "   - Validação cruzada\n",
    "\n",
    "5. **Tratamento de classes desbalanceadas:**\n",
    "   - SMOTE\n",
    "   - Class weights\n",
    "   - Focal Loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

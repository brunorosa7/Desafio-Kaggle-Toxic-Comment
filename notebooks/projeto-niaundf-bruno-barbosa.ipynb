{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1f42bc0",
   "metadata": {
    "papermill": {
     "duration": 0.004093,
     "end_time": "2026-01-30T20:56:45.055935",
     "exception": false,
     "start_time": "2026-01-30T20:56:45.051842",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Classificação de Comentários Tóxicos: Projeto de Capacitação - NIAUnDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83368cd2",
   "metadata": {
    "papermill": {
     "duration": 0.003081,
     "end_time": "2026-01-30T20:56:45.062258",
     "exception": false,
     "start_time": "2026-01-30T20:56:45.059177",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Introdução e Objetivo \n",
    "\n",
    "Este notebook apresenta uma solução para o Toxic Comment Classification Challenge, um desafio de Processamento de Linguagem Natural (NLP) proposto pela plataforma Kaggle.\n",
    "\n",
    "O objetivo central é criar um modelo de Machine Learning capaz de identificar e classificar diferentes tipos de toxicidade em comentários online. Diferente de uma classificação binária simples (Tóxico vs. Não Tóxico), este é um problema de classificação multi-rótulo (multi-label classification), onde um único comentário pode pertencer a várias categorias de toxicidade simultaneamente.\n",
    "\n",
    "### 1.1. Classes Alvo\n",
    "\n",
    "O modelo será treinado para prever a probabilidade de um comentário pertencer a cada uma das seguintes seis categorias:\n",
    "\n",
    "1. toxic (tóxico)\n",
    "2. severe_toxic (severamente tóxico)\n",
    "3. obscene (obsceno)\n",
    "4. threat (ameaça)\n",
    "5. insult (insulto)\n",
    "6. identity_hate (ódio à identidade)\n",
    "\n",
    "### 1.2. Propósito da Solução\n",
    "\n",
    "Além de cumprir os requisitos classificatórios do processo seletivo do Núcleo de Inteligência Artificial da UnDF, este projeto explora técnicas fundamentais de Ciência de Dados, incluindo:\n",
    "\n",
    "* Processamento e limpeza de dados textuais não estruturados.\n",
    "* Transformação de texto em representações numéricas (Vetorização).\n",
    "* Aplicação de algoritmos de aprendizado supervisionado para moderação de conteúdo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4c5666",
   "metadata": {
    "papermill": {
     "duration": 0.00296,
     "end_time": "2026-01-30T20:56:45.068235",
     "exception": false,
     "start_time": "2026-01-30T20:56:45.065275",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Metodologia Técnica e Importação de Bibliotecas\n",
    "\n",
    "Para resolver o desafio de classificação de comentários tóxicos, adotamos uma stack tecnológica baseada em Python, focada em eficiência e robustez para Processamento de Linguagem Natural (NLP). A escolha das bibliotecas segue os critérios técnicos de avaliação, visando uma solução clara e reprodutível.\n",
    "\n",
    "As ferramentas foram selecionadas para cobrir três pilares do projeto:\n",
    "\n",
    "### Manipulação de Dados (pandas, numpy)\n",
    "\n",
    "Essenciais para carregar os arquivos CSV e realizar operações vetoriais rápidas nas matrizes de dados.\n",
    "\n",
    "### Pré-processamento de Texto (re, nltk)\n",
    "\n",
    "**re (Regular Expressions):** Utilizada para limpeza profunda do texto (remoção de URLs, pontuação e caracteres especiais).\n",
    "nltk.corpus.stopwords: Permite a remoção de palavras comuns (como artigos e preposições) que não contribuem para a detecção de toxicidade.\n",
    "\n",
    "### Machine Learning (sklearn) \n",
    "\n",
    "**TfidfVectorizer:** Responsável por \"transformar textos em representações numéricas\", convertendo palavras em vetores ponderados pela relevância.\n",
    "\n",
    "**LogisticRegression & OneVsRestClassifier:** Como um comentário pode ter múltiplas classificações simultâneas (ex: ser tóxico E obsceno), utilizamos a estratégia One-vs-Rest para treinar um classificador binário independente para cada rótulo.\n",
    "\n",
    "**roc_auc_score:** Métrica de avaliação escolhida para medir a qualidade das predições, independente do limiar de decisão."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4e0013",
   "metadata": {
    "papermill": {
     "duration": 0.003059,
     "end_time": "2026-01-30T20:56:45.074270",
     "exception": false,
     "start_time": "2026-01-30T20:56:45.071211",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3adb98f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T20:56:45.082553Z",
     "iopub.status.busy": "2026-01-30T20:56:45.081978Z",
     "iopub.status.idle": "2026-01-30T20:56:49.233067Z",
     "shell.execute_reply": "2026-01-30T20:56:49.232065Z"
    },
    "papermill": {
     "duration": 4.15751,
     "end_time": "2026-01-30T20:56:49.235062",
     "exception": false,
     "start_time": "2026-01-30T20:56:45.077552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas importadas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Processamento de texto\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "print(\"Bibliotecas importadas com sucesso!\")\n",
    "\n",
    "# Baixar recursos do NLTK (se necessário)\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt', quiet=True)\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords', quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1237b9a0",
   "metadata": {
    "papermill": {
     "duration": 0.00332,
     "end_time": "2026-01-30T20:56:49.242137",
     "exception": false,
     "start_time": "2026-01-30T20:56:49.238817",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Carregamento e Análise Inicial dos Dados\n",
    "\n",
    "Nesta etapa, importamos os conjuntos de dados essenciais para o treinamento e validação do modelo. Utilizando a biblioteca pandas, transformamos os arquivos brutos (.csv) em DataFrames estruturados.\n",
    "\n",
    "A competição fornece dois arquivos principais:\n",
    "\n",
    "* **Dataset de Treino (train.csv):** Contém os comentários e os rótulos verdadeiros (ground truth) para as 6 classes de toxicidade. Este conjunto será usado para ensinar o algoritmo a reconhecer padrões.\n",
    "\n",
    "* **Dataset de Teste (test.csv):** Contém apenas os textos dos comentários, sem rótulos. O objetivo final é gerar predições para este conjunto e submetê-las ao Kaggle para avaliação de score.\n",
    "+1\n",
    "\n",
    "A verificação das dimensões (shape) e a visualização das primeiras linhas são cruciais para garantir que os dados foram carregados corretamente e para identificar a estrutura das colunas alvo: id, toxic, severe_toxic, obscene, threat, insult, identity_hate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47ac92ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T20:56:49.250576Z",
     "iopub.status.busy": "2026-01-30T20:56:49.250101Z",
     "iopub.status.idle": "2026-01-30T20:56:49.282295Z",
     "shell.execute_reply": "2026-01-30T20:56:49.281057Z"
    },
    "papermill": {
     "duration": 0.038458,
     "end_time": "2026-01-30T20:56:49.283798",
     "exception": true,
     "start_time": "2026-01-30T20:56:49.245340",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dados de treino...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/raw/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17/2037772782.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Carregar dados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Carregando dados de treino...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape: {train_df.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/raw/train.csv'"
     ]
    }
   ],
   "source": [
    "# Definir caminhos\n",
    "data_dir = Path('../data/raw')\n",
    "\n",
    "# Carregar dados\n",
    "print(\"Carregando dados de treino...\")\n",
    "train_df = pd.read_csv(data_dir / 'train.csv')\n",
    "print(f\"Shape: {train_df.shape}\")\n",
    "\n",
    "print(\"\\nCarregando dados de teste...\")\n",
    "test_df = pd.read_csv(data_dir / 'test.csv')\n",
    "print(f\"Shape: {test_df.shape}\")\n",
    "\n",
    "print(\"\\nCarregando sample submission...\")\n",
    "sample_submission = pd.read_csv(data_dir / 'sample_submission.csv')\n",
    "print(f\"Shape: {sample_submission.shape}\")\n",
    "\n",
    "# Colunas de toxicidade\n",
    "toxic_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "print(f\"\\nClasses de toxicidade: {toxic_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5e49de",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 4. Pré-processamento de Texto\n",
    "\n",
    "Para garantir que o modelo identifique comportamentos tóxicos com precisão, implementamos uma função de pré-processamento personalizada. Esta etapa é vital para reduzir o \"ruído\" estatístico e focar apenas no conteúdo semântico relevante dos comentários.\n",
    "\n",
    "A lógica aplicada no código acima inclui:\n",
    "\n",
    "* **Remoção de URLs:** Links e endereços web são eliminados via Expressões Regulares (Regex), pois não contribuem para a identificação de linguagem tóxica.\n",
    "* **Filtragem de Caracteres Especiais:** Símbolos e pontuações excessivas são removidos para evitar que variações gráficas (como \"tóxic0\" vs \"tóxico\") confundam o vetorizador.\n",
    "* **Normalização (Lowercasing):** Todas as palavras são convertidas para letras minúsculas, garantindo que o modelo trate \"ÓDIO\" e \"ódio\" como a mesma entidade linguística.\n",
    "* **Redução de Espaços:** Espaços duplos e quebras de linha desnecessárias são limpos para manter a integridade da estrutura de tokens.\n",
    "\n",
    "Esta abordagem técnica atende diretamente às Tarefas Esperadas do desafio, preparando os dados para serem transformados em representações numéricas eficientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0009cc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Pré-processa o texto:\n",
    "    - Remove URLs\n",
    "    - Remove caracteres especiais\n",
    "    - Converte para minúsculas\n",
    "    - Remove espaços extras\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    # Converter para string\n",
    "    text = str(text)\n",
    "    \n",
    "    # Remover URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remover caracteres especiais, manter apenas letras, números e espaços\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    \n",
    "    # Converter para minúsculas\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remover espaços extras\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Aplicar pré-processamento\n",
    "print(\"Pré-processando textos de treino...\")\n",
    "train_df['comment_text_processed'] = train_df['comment_text'].apply(preprocess_text)\n",
    "\n",
    "print(\"Pré-processando textos de teste...\")\n",
    "test_df['comment_text_processed'] = test_df['comment_text'].apply(preprocess_text)\n",
    "\n",
    "print(\"\\nExemplo de texto original:\")\n",
    "print(train_df['comment_text'].iloc[0][:200])\n",
    "print(\"\\nExemplo de texto processado:\")\n",
    "print(train_df['comment_text_processed'].iloc[0][:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cfab55",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 5. Transformação de Texto em Números (Vetorização)\n",
    "\n",
    "Modelos de aprendizado de máquina não compreendem texto bruto; eles operam sobre cálculos matemáticos. Portanto, para cumprir a tarefa de transformar textos em representações numéricas, utilizamos a técnica TF-IDF (Term Frequency-Inverse Document Frequency).\n",
    "\n",
    "Diferente de uma contagem simples de palavras (Bag of Words), o TF-IDF atribui pesos inteligentes aos termos:\n",
    "\n",
    "* **TF (Frequência do Termo):** Mede quantas vezes a palavra aparece no comentário.\n",
    "* **IDF (Frequência Inversa no Documento):** Diminui o peso de palavras que aparecem em muitos comentários (e.g., palavras genéricas) e aumenta o peso de palavras raras e específicas.\n",
    "\n",
    "Configurações Adotadas:\n",
    "\n",
    "* **ngram_range=(1, 2):** O modelo analisará unigramas (palavras isoladas) e bigramas (pares de palavras), permitindo captar contextos simples (ex: \"não gosto\" tem sentido diferente de \"gosto\").\n",
    "* **max_features:** Limitamos o vocabulário aos termos mais relevantes para otimizar a memória e reduzir o risco de overfitting.\n",
    "* **strip_accents='unicode':** Remove acentuação para garantir uniformidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a154eeb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Criar vetorizador TF-IDF\n",
    "# Limitar o número de features para não consumir muita memória\n",
    "max_features = 5000\n",
    "\n",
    "print(f\"Criando vetorizador TF-IDF com max_features={max_features}...\")\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=max_features,\n",
    "    ngram_range=(1, 2),  # Unigramas e bigramas\n",
    "    min_df=2,  # Palavra deve aparecer em pelo menos 2 documentos\n",
    "    max_df=0.95,  # Palavra não deve aparecer em mais de 95% dos documentos\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "# Treinar o vetorizador e transformar dados de treino\n",
    "print(\"\\nTreinando vetorizador e transformando dados de treino...\")\n",
    "X_train = vectorizer.fit_transform(train_df['comment_text_processed'])\n",
    "print(f\"Shape dos dados de treino: {X_train.shape}\")\n",
    "\n",
    "# Transformar dados de teste\n",
    "print(\"\\nTransformando dados de teste...\")\n",
    "X_test = vectorizer.transform(test_df['comment_text_processed'])\n",
    "print(f\"Shape dos dados de teste: {X_test.shape}\")\n",
    "\n",
    "# Labels\n",
    "y_train = train_df[toxic_cols].values\n",
    "print(f\"\\nShape dos labels: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5568f6b6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 6. Divisão dos Dados e Treinamento do Modelo\n",
    "\n",
    "\n",
    "Nesta etapa, definimos a arquitetura de aprendizado de máquina. Dado que este é um problema Multirrótulo (um comentário pode ter várias tags ao mesmo tempo), não podemos usar um classificador simples padrão.\n",
    "\n",
    "Para resolver isso, adotamos a estratégia One-vs-Rest (Um-contra-Todos).\n",
    "\n",
    "Componentes do Modelo:\n",
    "\n",
    "* **Estimador Base (Logistic Regression):** Escolhido por ser eficiente em dados de alta dimensão (como textos vetorizados) e oferecer boa interpretabilidade através dos coeficientes.\n",
    "* **Estratégia Wrapper (OneVsRestClassifier):** Este componente \"envolve\" a regressão logística e treina um classificador independente para cada uma das 6 classes de toxicidade.\n",
    "\n",
    "Essa abordagem nos permite calcular a probabilidade individual de cada tipo de ofensa, atendendo à exigência do edital de classificar múltiplas categorias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073d2cd1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dividir dados de treino em treino e validação\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train, y_train, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=None  # Não estratificar porque temos múltiplas classes\n",
    ")\n",
    "\n",
    "print(f\"Dados de treino: {X_train_split.shape}\")\n",
    "print(f\"Dados de validação: {X_val_split.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d71fe9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Usar OneVsRestClassifier com LogisticRegression\n",
    "# Isso treina um classificador binário para cada classe\n",
    "print(\"Treinando modelo (OneVsRest + LogisticRegression)...\")\n",
    "print(\"Isso pode levar alguns minutos...\")\n",
    "\n",
    "model = OneVsRestClassifier(\n",
    "    LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        random_state=42,\n",
    "        solver='lbfgs',\n",
    "        C=1.0\n",
    "    ),\n",
    "    n_jobs=-1  # Usar todos os cores disponíveis\n",
    ")\n",
    "\n",
    "# Treinar o modelo\n",
    "model.fit(X_train_split, y_train_split)\n",
    "\n",
    "print(\"\\nModelo treinado com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e0a66a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 7. Avaliação do Modelo \n",
    "\n",
    "Antes de gerar a submissão final para o Kaggle, é crucial avaliar a performance do modelo em um ambiente controlado. Para isso, utilizamos a técnica de validação cruzada simples (hold-out), onde separamos uma fração dos dados de treino para simular dados \"desconhecidos\".\n",
    "\n",
    "A Métrica Escolhida: **ROC-AUC** O desafio utiliza a métrica ROC-AUC (Area Under the Receiver Operating Characteristic Curve). Diferente da \"Acurácia\" (que pode ser enganosa em datasets desbalanceados), a ROC-AUC avalia a qualidade das probabilidades preditas.\n",
    "\n",
    "* Interpretação: Ela mede o quanto o modelo é capaz de distinguir entre classes (ex: separar um comentário \"tóxico\" de um \"não tóxico\").\n",
    "\n",
    "* Escala: Varia de 0 a 1. Quanto mais próximo de 1, melhor o modelo.\n",
    "\n",
    "Esta etapa permite estimar o \"Score obtido no Kaggle\" antes mesmo da submissão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955e9fd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T20:28:19.905261Z",
     "iopub.status.busy": "2026-01-30T20:28:19.904921Z",
     "iopub.status.idle": "2026-01-30T20:28:19.915125Z",
     "shell.execute_reply": "2026-01-30T20:28:19.913852Z",
     "shell.execute_reply.started": "2026-01-30T20:28:19.905232Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fazer previsões no conjunto de validação\n",
    "print(\"Fazendo previsões no conjunto de validação...\")\n",
    "y_val_pred = model.predict_proba(X_val_split)\n",
    "\n",
    "# Calcular ROC-AUC para cada classe\n",
    "print(\"\\n=== Métricas de Validação ===\")\n",
    "scores = {}\n",
    "for i, col in enumerate(toxic_cols):\n",
    "    score = roc_auc_score(y_val_split[:, i], y_val_pred[:, i])\n",
    "    scores[col] = score\n",
    "    print(f\"{col:20s}: {score:.4f}\")\n",
    "\n",
    "# Média dos scores\n",
    "mean_score = np.mean(list(scores.values()))\n",
    "print(f\"\\n{'Média':20s}: {mean_score:.4f}\")\n",
    "print(\"\\n(Quanto maior, melhor. Score máximo é 1.0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4f9ea4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 8. Previsões no Conjunto de Teste\n",
    "\n",
    "Com o modelo validado, aplicamos o conhecimento adquirido ao conjunto de Teste (test.csv). Estes são os dados \"do mundo real\" que o modelo nunca viu e sobre os quais ele será avaliado pelo sistema do Kaggle.\n",
    "\n",
    "**Processo de Inferência:**\n",
    "\n",
    "1. Carregamento do Template: Utilizamos o arquivo sample_submission.csv fornecido pela competição para garantir que os IDs dos comentários estejam na ordem exata exigida.\n",
    "\n",
    "2. Cálculo de Probabilidades: Novamente, utilizamos o método .predict_proba(). O objetivo não é apenas dizer se um comentário é tóxico ou não, mas atribuir um grau de certeza (probabilidade) a cada uma das 6 classes.\n",
    "\n",
    "3. Exportação: Os resultados são salvos no arquivo submission.csv, contendo as colunas obrigatórias: id, toxic, severe_toxic, obscene, threat, insult, identity_hate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e69708",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Treinar modelo final com todos os dados de treino\n",
    "print(\"Treinando modelo final com todos os dados de treino...\")\n",
    "model_final = OneVsRestClassifier(\n",
    "    LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        random_state=42,\n",
    "        solver='lbfgs',\n",
    "        C=1.0\n",
    "    ),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model_final.fit(X_train, y_train)\n",
    "print(\"Modelo final treinado!\")\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "print(\"\\nFazendo previsões no conjunto de teste...\")\n",
    "test_predictions = model_final.predict_proba(X_test)\n",
    "print(f\"Shape das previsões: {test_predictions.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e47256f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 9. Criar o Arquivo de Submissão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bee8bcc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Criar DataFrame de submissão\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id']\n",
    "})\n",
    "\n",
    "# Adicionar previsões para cada classe\n",
    "for i, col in enumerate(toxic_cols):\n",
    "    submission[col] = test_predictions[:, i]\n",
    "\n",
    "# Verificar formato\n",
    "print(\"=== Formato da Submissão ===\")\n",
    "print(f\"Shape: {submission.shape}\")\n",
    "print(f\"\\nPrimeiras linhas:\")\n",
    "display(submission.head())\n",
    "\n",
    "print(f\"\\nEstatísticas das previsões:\")\n",
    "display(submission[toxic_cols].describe())\n",
    "\n",
    "# Verificar se está no formato correto\n",
    "print(f\"\\nColunas esperadas: {list(sample_submission.columns)}\")\n",
    "print(f\"Colunas criadas: {list(submission.columns)}\")\n",
    "assert list(submission.columns) == list(sample_submission.columns), \"Colunas não correspondem!\"\n",
    "print(\"\\n✓ Formato correto!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5035d227",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 10. Salvar Arquivo de Submissão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e7f1df",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Criar diretório para submissões\n",
    "submission_dir = Path('../submissions')\n",
    "submission_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Salvar arquivo de submissão\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "filename = f'submission_{timestamp}.csv'\n",
    "filepath = submission_dir / filename\n",
    "\n",
    "submission.to_csv(filepath, index=False)\n",
    "print(f\"Arquivo de submissão salvo em: {filepath}\")\n",
    "print(f\"Tamanho do arquivo: {filepath.stat().st_size / 1024:.2f} KB\")\n",
    "\n",
    "# Também salvar como submission.csv (mais fácil de encontrar)\n",
    "submission.to_csv(submission_dir / 'submission.csv', index=False)\n",
    "print(f\"\\nTambém salvo como: {submission_dir / 'submission.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a1b6a7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 11. Conclusão e Resultados Obtidos\n",
    "\n",
    "Este projeto apresenta uma solução sistemática e bem fundamentada para o desafio de classificação de comentários tóxicos proposto pela etapa de capacitação do Edital N° 01/2025 - NIAUnDF. A abordagem adotada utilizou técnicas consolidadas de Processamento de Linguagem Natural, combinando a vetorização TF-IDF com a eficiência da Regressão Logística em uma estratégia multirrótulo.\n",
    "\n",
    "O modelo desenvolvido mostrou-se eficiente e interpretável, **alcançando um score ROC-AUC médio de 0.9696 (96.96%)** no conjunto de validação, o que demonstra sua eficácia prática na tarefa proposta. Além de gerar predições competitivas e o arquivo de submissão final, esta solução estabelece uma base sólida para melhorias futuras, servindo como ponto de partida para a exploração de arquiteturas mais avançadas, como Deep Learning (BERT) e técnicas de balanceamento de classes.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31259,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.231727,
   "end_time": "2026-01-30T20:56:50.007581",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-30T20:56:41.775854",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
